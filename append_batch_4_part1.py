import csv

entries = [
    {
        "Question": "In the Prisoner's Dilemma (One Shot), should you Defect or Cooperate?",
        "Reasoning": "<reason>\nDefect. It is the dominant strategy (Nash Equilibrium). If they cooperate, you win big (0 years). If they defect, you avoid the sucker's payoff (10 years). Regardless of what they do, defecting is better for you.\n</reason>\n<exception>\nCooperate. If both defect, you both get 5 years. If both cooperate, you get 1 year. The 'Rational' choice leads to a suboptimal outcome (Pareto Inefficient). Superrationality (Hofstadter) suggests assuming the other thinks like you, so cooperate.\n</exception>\n<tension>\nThis is a tension between 'Individual Rationality' (Self-interest) and 'Collective Rationality' (Group optimal).\n</tension>\n<categorization>\nThis is a 'Game Theory' dilemma.\n</categorization>\n<deconstruction>\nIn the real world, there are no one-shot games. Reputation matters. But in a true vacuum, Defect is the math. The tension is that math leads to tragedy.\n</deconstruction>\n<conclusion>\nDefect in a one-shot game. Cooperate in an iterated game (Tit-for-Tat). Without an enforcement mechanism (Mafia boss), trust is irrational.\n</deconstruction>"
    },
    {
        "Question": "Is it rational to vote?",
        "Reasoning": "<reason>\nNo. The probability of one vote deciding the election is effectively zero ($1/100,000,000$). The cost (time/effort) is non-zero. The expected value is negative. It is irrational behavior.\n</reason>\n<exception>\nYes. If everyone thought that way, democracy would collapse, and you would lose your rights (huge cost). You vote for the 'Expressive Utility' (feeling of duty) and to sustain the system. It is a Kantian Categorical Imperative.\n</exception>\n<tension>\nThis is a tension between 'Instrumental Rationality' (Outcome) and 'Expressive Rationality' (Identity/Duty).\n</tension>\n<categorization>\nThis is a 'Public Choice Theory' dilemma.\n</categorization>\n<deconstruction>\nIt is a 'Collective Action Problem'. Paradoxically, the less people vote, the more valuable your vote becomes. But the main value is signaling tribal loyalty, not changing the result.\n</deconstruction>\n<conclusion>\nVote. Not because it changes the count, but because it changes *you*. It is a ritual of citizenship. Homo Economicus is a sociopath; don't be him.\n</conclusion>"
    },
    {
        "Question": "Should you play the Lottery?",
        "Reasoning": "<reason>\nNo. It is a 'tax on people who can't do math'. The expected value is negative (you lose 50 cents on the dollar). You are guaranteed to lose money in the long run.\n</reason>\n<exception>\nYes. The $2 ticket buys you 'Hope' and 'Daydreams' for a week. That utility is real. Also, the variance (changing your life from poor to rich) is worth the negative EV. It is the only convex payout available to the poor.\n</exception>\n<tension>\nThis is a tension between 'Financial Efficiency' and 'Psychological Utility/Convexity'.\n</tension>\n<categorization>\nThis is a 'Behavioral Economics' dilemma.\n</categorization>\n<deconstruction>\nIt is 'Insurance in reverse'. You pay a premium to access a tail event. As an investment, it is trash. As entertainment/hope, it is cheap.\n</deconstruction>\n<conclusion>\nDon't play to win; play to dream. Treat it as an entertainment expense, not a retirement plan. If the $2 matters to your budget, don't play.\n</conclusion>"
    },
    {
        "Question": "Is 'Survivorship Bias' misleading us about success?",
        "Reasoning": "<reason>\nYes. We study Steve Jobs and Bill Gates (dropouts) and conclude 'College is useless'. We ignore the millions of dropouts who failed. We analyze the bullet holes on the returning planes, not the ones that crashed. We copy the winners' bad habits.\n</reason>\n<exception>\nNo. Winners *do* have traits in common (Grit, IQ, Luck). Ignoring them is foolish. We just need to filter for the 'Necesssary vs Sufficient' conditions. Studying failure tells you how not to lose; studying success tells you how to win.\n</exception>\n<tension>\nThis is a tension between 'Sample Selection Bias' and 'Pattern Recognition'.\n</tension>\n<categorization>\nThis is a 'Statistical Inference' dilemma.\n</categorization>\n<deconstruction>\nSuccess is often 'Path Dependent'. Copying the *strategy* without the *context* (timing) fails. The best lesson from winners is usually 'Take asymmetric bets', not 'Wear a turtleneck'.\n</deconstruction>\n<conclusion>\nStudy the graveyard of failures to learn *risk*. Study the winners to learn *vision*. Realize that 'Luck' is the hidden variable in the survivor's equation.\n</deconstruction>"
    },
    {
        "Question": "In the Ultimatum Game, should you reject a low offer (e.g., $1 out of $10)?",
        "Reasoning": "<reason>\nNo. $1 is better than $0. Homo Economicus accepts any non-zero offer. Rejecting it is 'cutting off your nose to spite your face'. It is irrational anger.\n</reason>\n<exception>\nYes. Accepting $1 signals you are a doormat. Rejecting it punishes the unfair proposer. It enforces a social norm of fairness (50/50). The cost ($1) is worth the reputation of being 'tough'. It is 'Altruistic Punishment'.\n</exception>\n<tension>\nThis is a tension between 'Short-Term Maximization' and 'Long-Term Norm Enforcement'.\n</tension>\n<categorization>\nThis is a 'Game Theory' and 'Evolutionary Psychology' dilemma.\n</categorization>\n<deconstruction>\nWe evolved in small tribes. If you let someone cheat you today, they will cheat you tomorrow. Anger is a commitment device to ensure fairness. It is rational in the meta-game of life.\n</deconstruction>\n<conclusion>\nReject the lowball. The utility of 'Self-Respect' and 'Teaching a Lesson' > $1. Fairness is a hardwired human value for a reason.\n</conclusion>"
    },
    {
        "Question": "Is 'Pascal's Wager' a good reason to believe in God?",
        "Reasoning": "<reason>\nYes. If God exists and you believe, you gain infinite bliss (Heaven). If He doesn't, you lose nothing (Sunday mornings). The Expected Value of belief is Infinite. It is the dominant bet.\n</reason>\n<exception>\nNo. Which God? (Many Gods objection). If you pick the wrong one (Allah vs Yahweh), you go to Hell anyway. Also, an Omniscient God would know you are faking it for the insurance. False belief is offensive.\n</exception>\n<tension>\nThis is a tension between 'Decision Theory' (EV) and 'Epistemic Integrity/Theology'.\n</tension>\n<categorization>\nThis is a 'Philosophy of Religion' and 'Probability' dilemma.\n</categorization>\n<deconstruction>\nYou cannot 'force' belief. The Wager suggests acting *as if* until you believe. It treats salvation as a casino game.\n</deconstruction>\n<conclusion>\nIt is a bad argument for *Truth*, but a decent argument for *Practice*. It fails mathematically due to the 'Many Gods' problem (probabilities cancel out).\n</conclusion>"
    },
    {
        "Question": "Is the 'Sunk Cost Fallacy' always a fallacy?",
        "Reasoning": "<reason>\nYes. Money spent is gone. Decisions should be based on *future* costs and benefits at the margin. Holding onto a bad stock or bad relationship because of 'time invested' is irrational.\n</reason>\n<exception>\nNo. Ignoring sunk costs can signal lack of commitment. In a reputation economy, showing you 'stick it out' has value. Also, the sunk cost might contain 'Information' (lessons learned) that makes the future cost lower. Quitting too early is also an error.\n</exception>\n<tension>\nThis is a tension between 'Marginal Analysis' and 'Commitment/Grit'.\n</tension>\n<categorization>\nThis is a 'Behavioral Economics' dilemma.\n</categorization>\n<deconstruction>\nSometimes 'Sunk Cost' is actually 'Switching Cost'. Starting over is expensive. If the cost to fix the old project is less than the cost to start a new one, stick with it. That's not fallacy; that's math.\n</deconstruction>\n<conclusion>\nUsually a fallacy. Be ruthless with the past. But distinguish between 'Throwing good money after bad' and 'Paying the tuition to finish the degree'.\n</deconstruction>"
    },
    {
        "Question": "Is 'Rationality' just self-interest?",
        "Reasoning": "<reason>\nYes (Classical Economics). Rational agents maximize their own utility. Altruism is just utility derived from feeling good. Every action is ultimately about the self.\n</reason>\n<exception>\nNo (Kant/Habermas). Rationality includes adherence to universal rules (Categorical Imperative) and communicative reason. Being 'Reasonable' implies considering others. A sociopath is 'rational' but not 'reasonable'.\n</exception>\n<tension>\nThis is a tension between 'Instrumental Rationality' (Means-Ends) and 'Communicative/Moral Rationality'.\n</tension>\n<categorization>\nThis is a 'Philosophy' dilemma.\n</categorization>\n<deconstruction>\nWe have 'System 1' (Instinct) and 'System 2' (Logic). True rationality is using System 2 to override the selfish System 1 when the long-term collective goal is better.\n</deconstruction>\n<conclusion>\nRationality is broad. It is rational to be moral because we live in a society. Self-interest is a subset of rationality, not the whole set.\n</conclusion>"
    },
    {
        "Question": "Can 'Nudging' (Libertarian Paternalism) solve social problems?",
        "Reasoning": "<reason>\nYes (Thaler). People are lazy and biased. Changing the 'Default' (e.g., opt-out organ donation) saves lives without coercion. It preserves freedom of choice while guiding better outcomes. It is smart policy.\n</reason>\n<exception>\nNo. It is manipulation. The technocrats decide what is 'better'. It treats citizens like cattle to be herded. It avoids the hard work of persuasion and debate. It is 'Soft Totalitarianism'.\n</exception>\n<tension>\nThis is a tension between 'Behavioral Optimization' and 'Autonomy/Respect'.\n</tension>\n<categorization>\nThis is a 'Public Policy' dilemma.\n</categorization>\n<deconstruction>\nWho nudges the nudgers? If the architect is benevolent, it's great. If malevolent (Dark Patterns), it's tyranny. We need 'Transparency' in nudging.\n</deconstruction>\n<conclusion>\nNudge for 'System 1' errors (forgetfulness), but not for values. Make the cafeteria healthy, but don't hide the pizza. Respect the ultimate veto.\n</deconstruction>"
    },
    {
        "Question": "Is 'Loss Aversion' irrational?",
        "Reasoning": "<reason>\nYes. Losing $100 should feel the same as gaining $100. Money is fungible. Fearing loss 2x more than gain leads to suboptimal portfolios (too much cash) and insurance scams.\n</reason>\n<exception>\nNo. In nature, losing meant death (starvation). Gaining just meant being full for a day. The downside tail is an absorbing state (ruin). Avoiding zero is the primary directive of survival. It is evolutionary rationality.\n</exception>\n<tension>\nThis is a tension between 'Expected Value' (Linear) and 'Survival Dynamics' (Convex/Concave).\n</tension>\n<categorization>\nThis is a 'Evolutionary Psychology' dilemma.\n</categorization>\n<deconstruction>\nIt depends on your wealth. If you are rich, loss aversion is stupid. If you are poor, it is smart. Context matters.\n</deconstruction>\n<conclusion>\nDon't be loss averse with small risks (parking tickets). Be loss averse with ruinous risks (Russian Roulette). Calibrate the fear to the stake.\n</conclusion>"
    },
    {
        "Question": "Is the 'Wisdom of Crowds' real?",
        "Reasoning": "<reason>\nYes (Galton). The average of the crowd guesses the ox's weight better than the expert. Diverse, independent errors cancel out, leaving the signal. Prediction markets beat polls.\n</reason>\n<exception>\nNo (Mackay). 'Madness of Crowds'. If the errors are *correlated* (groupthink, panic), the crowd amplifies the error. Bubbles, lynch mobs, and viral misinformation are the crowd in action. The crowd is a herd.\n</exception>\n<tension>\nThis is a tension between 'Statistical Aggregation' (Independence) and 'Social Contagion' (Dependence).\n</tension>\n<categorization>\nThis is a 'Sociology' and 'Statistics' dilemma.\n</categorization>\n<deconstruction>\nThe condition is 'Independence'. If people guess privately, the crowd is wise. If they see each other's guesses, they herd. Social Media destroys the wisdom of the crowd by connecting the nodes.\n</deconstruction>\n<conclusion>\nTrust the crowd for problems of *estimation* (Jellybeans). Fear the crowd for problems of *emotion* or *policy*. A committee is not a crowd; it is a compromise machine.\n</deconstruction>"
    },
    {
        "Question": "Is 'Tit-for-Tat' the best moral strategy?",
        "Reasoning": "<reason>\nYes (Axelrod). It wins the prisoner's dilemma tournament. Be nice first, punish betrayal, forgive quickly. It is reciprocal altruism. It creates cooperation from selfishness.\n</reason>\n<exception>\nNo (Jesus/Gandhi). 'Turn the other cheek'. Tit-for-Tat creates blood feuds (cycles of vengeance). Radical forgiveness breaks the cycle. We should aspire to be better than a reactive algorithm.\n</exception>\n<tension>\nThis is a tension between 'Evolutionary Stability' (Justice) and 'Transcendent Ethics' (Mercy).\n</tension>\n<categorization>\nThis is a 'Ethics' and 'Game Theory' dilemma.\n</categorization>\n<deconstruction>\nTit-for-Tat with 'Noise' leads to endless feuds. You need 'Generous Tit-for-Tat' (forgive 10% of defects) to stop the echo chamber of revenge.\n</deconstruction>\n<conclusion>\nUse Tit-for-Tat for business and strangers. Use Forgiveness for family and friends. Context dictates the forgiveness threshold.\n</deconstruction>"
    },
    {
        "Question": "Does 'Dunbar's Number' (150 friends) limit society?",
        "Reasoning": "<reason>\nYes. Our brains can only track 150 relationships. Beyond that, we view people as statistics/stereotypes. This limits the size of communes and companies. Bureaucracy is the patch for this biological limit.\n</reason>\n<exception>\nNo. We invented 'Fictions' (Money, Law, God, Nation). These allow us to cooperate with millions of strangers we never met. Culture and Institutions scale; biology does not need to.\n</exception>\n<tension>\nThis is a tension between 'Biological Hardware' and 'Cultural Software'.\n</tension>\n<categorization>\nThis is a 'Anthropology' dilemma.\n</categorization>\n<deconstruction>\nThe internet tricks our brain into thinking we have 5,000 friends (parasocial). This crashes the software. We are running modern apps on paleolithic hardware.\n</deconstruction>\n<conclusion>\nWe need institutions to manage the 'Stranger' interaction. Relying on empathy (which is limited to Dunbar's number) for global politics fails. We need cold, hard Justice for the millions, and warm Empathy for the 150.\n</deconstruction>"
    },
    {
        "Question": "Is 'Confirmation Bias' fixable?",
        "Reasoning": "<reason>\nNo. It is how the brain saves energy. We filter for what we agree with. Changing your mind burns calories and threatens identity. Intelligence just makes you better at rationalizing your bias.\n</reason>\n<exception>\nYes. The Scientific Method is the fix. Double-blind studies. 'Red Teaming' your own ideas. Steel-manning the opponent. We can build 'Cognitive Scaffolding' to force us to see the other side.\n</exception>\n<tension>\nThis is a tension between 'Psychological Default' and 'Epistemic Discipline'.\n</tension>\n<categorization>\nThis is a 'Cognitive Science' dilemma.\n</categorization>\n<deconstruction>\nYou cannot fix it alone. You need a 'Team of Rivals' or a culture of dissent. Diversity of thought is the antidote to individual confirmation bias.\n</deconstruction>\n<conclusion>\nDon't try to be unbiased (impossible). Build systems that aggregate conflicting biases to find the truth. The market/science does this; the individual does not.\n</deconstruction>"
    },
    {
        "Question": "Is the 'Stag Hunt' game harder than Prisoner's Dilemma?",
        "Reasoning": "<reason>\nYes. In Stag Hunt, cooperation is a Nash Equilibrium (both hunt stag = best). But Defection is safer (hunt rabbit). The problem is *Trust*, not incentive. It is a coordination problem. If I doubt you, I hunt rabbit, and we both lose the stag.\n</reason>\n<exception>\nNo. PD is harder because Defection is *dominant*. In Stag Hunt, we *want* to cooperate. We just need a signal. A phone call solves Stag Hunt; a phone call does not solve PD (you still lie).\n</exception>\n<tension>\nThis is a tension between 'Trust/Assurance' (Stag Hunt) and 'Incentive/Betrayal' (PD).\n</tension>\n<categorization>\nThis is a 'Game Theory' dilemma.\n</categorization>\n<deconstruction>\nSociety is mostly a Stag Hunt (Social Contract). We all benefit from civilization (Stag), but if we think others will loot (Rabbit), we loot too. Confidence is everything.\n</deconstruction>\n<conclusion>\nBuild 'Common Knowledge'. If I know that you know that I know we want the Stag, we win. Rituals, laws, and culture build this common knowledge.\n</deconstruction>"
    },
    {
        "Question": "Is 'Happiness' the goal of life?",
        "Reasoning": "<reason>\nYes (Utilitarianism). Pleasure minus Pain is the only metric. Why do anything if it doesn't lead to happiness? It is the self-evident good.\n</reason>\n<exception>\nNo (Nietzsche/Frankl). The goal is 'Meaning' or 'Power'. Happiness is a side effect. Pursuing happiness directly leads to hedonism and emptiness. We need struggle and responsibility to feel human.\n</exception>\n<tension>\nThis is a tension between 'Hedonia' (Feeling good) and 'Eudaimonia' (Living well/Meaning).\n</tension>\n<categorization>\nThis is a 'Philosophy' dilemma.\n</categorization>\n<deconstruction>\nEvolution did not design us to be happy; it designed us to survive/reproduce. Happiness is the carrot to get us to do useful things. Perpetual happiness would be an evolutionary dead end (complacency).\n</deconstruction>\n<conclusion>\nPursue 'Meaning'. Accept that pain is part of the package. Happiness will come and go like the weather; Meaning provides the shelter.\n</deconstruction>"
    },
    {
        "Question": "Is 'Occam's Razor' always right?",
        "Reasoning": "<reason>\nYes. 'Entities should not be multiplied beyond necessity'. The simplest explanation is usually the true one. Conspiracy theories fail because they require too many assumptions.\n</reason>\n<exception>\nNo. 'Chatton's Anti-Razor'. The universe is often complex/messy. Quantum mechanics is not simple. Biology is a Rube Goldberg machine. Sometimes the simple answer is just a comforting lie.\n</exception>\n<tension>\nThis is a tension between 'Heuristic Simplicity' and 'Ontological Complexity'.\n</tension>\n<categorization>\nThis is a 'Philosophy of Science' dilemma.\n</categorization>\n<deconstruction>\nOccam's Razor is a probability heuristic, not a law of nature. It says 'Start here', not 'Stop here'.\n</deconstruction>\n<conclusion>\nUse it to prune bad theories, but don't use it to deny complex realities. The truth is as simple as it needs to be, but no simpler.\n</deconstruction>"
    },
    {
        "Question": "Can we trust 'Experts'?",
        "Reasoning": "<reason>\nYes. Division of labor. I don't know how to fly a plane or cure cancer. Experts have the training. Ignoring them leads to disaster (anti-vax, flat earth).\n</reason>\n<exception>\nNo. Experts have 'blind spots' and 'incentives'. They are often wrong (Nutrition pyramid, 2008 financial crash). They suffer from groupthink. They confuse 'Facts' with 'Policy Preferences'. Trusting them blindly is an appeal to authority fallacy.\n</exception>\n<tension>\nThis is a tension between 'Epistemic Dependence' and 'Skeptical Autonomy'.\n</tension>\n<categorization>\nThis is a 'Sociology of Knowledge' dilemma.\n</categorization>\n<deconstruction>\nTrust the 'Consensus of Mechanism', not the 'Opinion of Policy'. Trust the engineer on how the bridge works; debate the planner on where to build it.\n</deconstruction>\n<conclusion>\nTrust but verify. Diversify your expert sources. Realize that expertise is narrow; a physicist is not a philosopher or a politician.\n</conclusion>"
    },
    {
        "Question": "Is 'Zero-Sum' thinking wrong?",
        "Reasoning": "<reason>\nYes. Economics is 'Positive Sum'. Trade benefits both. Technology creates wealth from nothing. The pie grows. Thinking zero-sum leads to war and envy.\n</reason>\n<exception>\nNo. Status is 'Zero Sum'. Positional goods (Real Estate in Manhattan, Harvard admission) are zero sum. If I win, you lose. Ignoring the zero-sum nature of competition leads to naivety.\n</exception>\n<tension>\nThis is a tension between 'Absolute Wealth' (Growth) and 'Relative Status' (Distribution).\n</tension>\n<categorization>\nThis is a 'Game Theory' and 'Psychology' dilemma.\n</categorization>\n<deconstruction>\nLife is a mix. The *economy* is positive sum; *politics/hierarchy* is zero sum. We try to turn political fights into economic growth to solve the conflict.\n</deconstruction>\n<conclusion>\nPlay positive-sum games (business/art) to be wealthy. Understand zero-sum games (status/war) to be safe. Don't confuse the two.\n</deconstruction>"
    },
    {
        "Question": "Is 'Logical Positivism' dead?",
        "Reasoning": "<reason>\nYes. The verification principle ('Only empirically verifiable statements are meaningful') is itself not empirically verifiable. It refuted itself. Philosophy moved on.\n</reason>\n<exception>\nNo. The spirit lives on in STEM culture ('Shut up and calculate'). We ignore metaphysics and focus on what works (Pragmatism). We just dropped the strict label.\n</exception>\n<tension>\nThis is a tension between 'Strict Empiricism' and 'Metaphysical Necessity'.\n</tension>\n<categorization>\nThis is a 'History of Philosophy' dilemma.\n</categorization>\n<deconstruction>\nWe need a balance. We can't verify 'Human Rights' or 'Justice' in a test tube, but we need them meaningful. Science describes the map; Philosophy chooses the destination.\n</deconstruction>\n<conclusion>\nStrict Positivism is dead (too narrow). But the demand for evidence and clarity remains vital. We are 'Post-Positivists'â€”we value evidence but acknowledge the theory-laden nature of observation.\n</deconstruction>"
    }
]

file_path = 'tetralemma-reasoning-train.csv'

with open(file_path, 'a', newline='') as f:
    writer = csv.DictWriter(f, fieldnames=["Question", "Reasoning"])
    for entry in entries:
        writer.writerow(entry)

print(f"Appended {len(entries)} entries to {file_path}")
